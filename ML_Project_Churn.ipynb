{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb63abf",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning – Project 2025\n",
    "\n",
    "## Dataset: Customer Churn\n",
    "\n",
    "This notebook corresponds to the project instructions.\n",
    "\n",
    "We chose **Dataset A: Churn Data** (from `ChurnData.csv`).\n",
    "\n",
    "We will follow the required steps:\n",
    "\n",
    "\n",
    "1. Dataset selection and problem definition\n",
    "\n",
    "2. Scenario / about the dataset\n",
    "\n",
    "3. Data loading and summary\n",
    "\n",
    "4. Data wrangling / preprocessing\n",
    "\n",
    "5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "6. Model development (multiple ML algorithms)\n",
    "\n",
    "7. Model evaluation (metrics & plots)\n",
    "\n",
    "8. Model refinement and conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20258ddf",
   "metadata": {},
   "source": [
    "## Step 2 – Scenario / About the Dataset\n",
    "\n",
    "You are working as a **data analyst** for a telecom company.\n",
    "\n",
    "The company wants to understand and **predict customer churn** (whether a customer is likely to leave).\n",
    "\n",
    "\n",
    "**Goal:** build a machine learning solution that, based on customer attributes (tenure, income, services, etc.),\n",
    "\n",
    "predicts whether the customer will churn.\n",
    "\n",
    "\n",
    "**Type of problem:** this is a **supervised classification** problem because:\n",
    "\n",
    "- The target variable `churn` takes discrete values (0 = no churn, 1 = churn).\n",
    "\n",
    "- We want to assign each customer to one of these classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a099b6c",
   "metadata": {},
   "source": [
    "## Step 3 – Data Loading and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676174f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load churn dataset\n",
    "df = pd.read_csv(\"/mnt/data/Project/ChurnData.csv\")\n",
    "\n",
    "# Basic info\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd258bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shape of the data (rows, columns)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa467cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column names and data types\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic statistics for numerical features\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28172b6d",
   "metadata": {},
   "source": [
    "### Short description of the attributes\n",
    "Below is an example description; you can adapt the wording if needed:\n",
    "\n",
    "- `tenure`: Number of months the customer has been with the company.\n",
    "\n",
    "- `age`: Age of the customer.\n",
    "\n",
    "- `address`: Related to how long the customer has lived at the current address.\n",
    "\n",
    "- `income`: Normalized income indicator.\n",
    "\n",
    "- `ed`: Education level.\n",
    "\n",
    "- `employ`: Years of employment.\n",
    "\n",
    "- `equip`: Type or presence of company equipment.\n",
    "\n",
    "- `callcard`, `wireless`, `voice`, `pager`, `internet`: Usage or subscription indicators for different services.\n",
    "\n",
    "- `longmon`, `tollmon`, `equipmon`, `cardmon`, `wiremon`: Monthly billing amounts for different services.\n",
    "\n",
    "- `longten`, `tollten`, `cardten`: Tenure-related metrics for different services.\n",
    "\n",
    "- `callwait`, `confer`, `ebill`: Service features (call waiting, conference, electronic billing).\n",
    "\n",
    "- `loglong`, `logtoll`, `lninc`: Log-transformed numeric features.\n",
    "\n",
    "- `custcat`: Customer category (segment).\n",
    "\n",
    "- `churn`: Target variable (1 = churn, 0 = no churn).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81458d5",
   "metadata": {},
   "source": [
    "## Step 4 – Data Wrangling / Pre‑processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86daf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: handle missing values (if any)\n",
    "# - For numerical columns: fill with median\n",
    "# - For categorical columns: fill with mode\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "df.isna().sum().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features X and target y\n",
    "target_col = \"churn\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1930cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scaling numerical features (many models work better with scaled data)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1435ca",
   "metadata": {},
   "source": [
    "**Summary of preprocessing:**\n",
    "- Checked and imputed missing values.\n",
    "- Split data into training and test sets.\n",
    "- Scaled numerical features for the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be46afc",
   "metadata": {},
   "source": [
    "## Step 5 – Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribution of target variable (churn)\n",
    "y.value_counts().plot(kind='bar')\n",
    "plt.title('Class distribution: churn')\n",
    "plt.xlabel('Churn (0 = no, 1 = yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: histogram of a few important numeric features\n",
    "cols_to_plot = [\"tenure\", \"age\", \"income\", \"longmon\"]\n",
    "\n",
    "for col in cols_to_plot:\n",
    "    df[col].hist(bins=20)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation matrix (numeric features only)\n",
    "import numpy as np\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple visualization of correlations with churn\n",
    "corr_with_churn = corr['churn'].sort_values(ascending=False)\n",
    "corr_with_churn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8715f",
   "metadata": {},
   "source": [
    "**Key findings (to be adapted after running the notebook):**\n",
    "- Some features such as tenure, income, and long distance usage may correlate with churn.\n",
    "- Class distribution may be slightly imbalanced (depending on counts).\n",
    "- Certain service-related features (e.g. `ebill`, `internet`) might be associated with higher or lower churn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a77ca7",
   "metadata": {},
   "source": [
    "## Step 6 – Model Development\n",
    " We will train **multiple machine learning algorithms**:\n",
    "- Logistic Regression (baseline, commonly taught in class).\n",
    "- Random Forest Classifier.\n",
    "- Gradient Boosting Classifier (often more advanced, may qualify as “not taught in class”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = clf\n",
    "    print(f\"Trained: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd1d15",
   "metadata": {},
   "source": [
    "## Step 7 – Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a697e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in trained_models.items():\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    })\n",
    "    \n",
    "    print(\"==\", name, \"==\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1-score:\", f1)\n",
    "    if auc is not None:\n",
    "        print(\"ROC AUC:\", auc)\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: simple bar plot of F1-score by model\n",
    "results_df.set_index(\"model\")[\"f1\"].plot(kind=\"bar\")\n",
    "plt.title(\"F1-score by model\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07010927",
   "metadata": {},
   "source": [
    "## Step 8 – Model Refinement & Conclusions\n",
    "\n",
    "### Comparison of models\n",
    "\n",
    "After running the notebook, compare the metrics:\n",
    "\n",
    "- Which model has the highest **F1-score**?\n",
    "\n",
    "- Which model has the best **ROC AUC** (when available)?\n",
    "\n",
    "- Is there a trade‑off between precision and recall?\n",
    "\n",
    "\n",
    "### Possible refinements\n",
    "\n",
    "- Try **hyperparameter tuning** (GridSearchCV or RandomizedSearchCV) for the best models.\n",
    "\n",
    "- Perform **feature selection** or regularization to reduce overfitting.\n",
    "\n",
    "- Try additional or more advanced algorithms (e.g. XGBoost, LightGBM) if available.\n",
    "\n",
    "- Handle possible class imbalance (e.g. using `class_weight='balanced'` or resampling techniques).\n",
    "\n",
    "\n",
    "### Limitations of the models\n",
    "\n",
    "- The dataset size and quality may limit generalization.\n",
    "\n",
    "- Features may not capture all reasons for customer churn.\n",
    "\n",
    "- Models assume that the future will be similar to the historical data.\n",
    "\n",
    "\n",
    "### Final recommendation to the client\n",
    "\n",
    "- Choose the model with the best balance between recall (detecting churners) and precision (avoiding false alarms).\n",
    "\n",
    "- Use the predictions to **prioritize retention campaigns** for customers at high risk of churn.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
